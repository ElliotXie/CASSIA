// Script to generate search index from markdown files
// Run with: node scripts/generate-search-index.mjs

import fs from 'fs'
import path from 'path'
import matter from 'gray-matter'
import { fileURLToPath } from 'url'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

const CONTENT_DIR = path.join(__dirname, '..', 'content')
const OUTPUT_FILE = path.join(__dirname, '..', 'lib', 'search-data.ts')

function getAllMarkdownFiles(dir, files = []) {
  const entries = fs.readdirSync(dir, { withFileTypes: true })

  for (const entry of entries) {
    const fullPath = path.join(dir, entry.name)
    if (entry.isDirectory()) {
      getAllMarkdownFiles(fullPath, files)
    } else if (entry.name.endsWith('.md')) {
      files.push(fullPath)
    }
  }

  return files
}

function parseMarkdownFile(filePath) {
  const content = fs.readFileSync(filePath, 'utf-8')
  const { data: frontmatter, content: body } = matter(content)

  // Extract path components from file path
  // Example: content/en/docs/r/introduction.md -> { locale: 'en', section: 'docs', lang: 'r', slug: 'introduction' }
  const relativePath = path.relative(CONTENT_DIR, filePath)
  const parts = relativePath.split(path.sep)

  if (parts.length < 4) {
    console.warn(`Skipping file with unexpected path structure: ${filePath}`)
    return null
  }

  const locale = parts[0] // 'en' or 'zh'
  const section = parts[1] // 'docs' or 'vignette'
  const lang = parts[2] // 'r' or 'python'
  const slug = parts[3].replace('.md', '')

  // Get title from frontmatter or derive from slug
  const title = frontmatter.title || slug.split('-').map(w => w.charAt(0).toUpperCase() + w.slice(1)).join(' ')

  // Clean the body content for search preview
  const cleanContent = body
    .replace(/```[\s\S]*?```/g, '') // Remove code blocks
    .replace(/!\[.*?\]\(.*?\)/g, '') // Remove images
    .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1') // Convert links to text
    .replace(/#{1,6}\s/g, '') // Remove heading markers
    .replace(/[*_`]/g, '') // Remove formatting
    .replace(/\n+/g, ' ') // Replace newlines with spaces
    .replace(/\s+/g, ' ') // Normalize whitespace
    .trim()
    .substring(0, 200) // First 200 chars

  // Skip "To Be Updated" pages
  if (title === 'To Be Updated' || cleanContent.length < 10) {
    return null
  }

  return {
    title,
    slug,
    section,
    lang,
    locale,
    content: cleanContent,
    url: `/${locale}/${section}/${lang}/${slug}`
  }
}

function generateSearchIndex() {
  console.log('Generating search index...')
  console.log(`Content directory: ${CONTENT_DIR}`)

  const markdownFiles = getAllMarkdownFiles(CONTENT_DIR)
  console.log(`Found ${markdownFiles.length} markdown files`)

  const searchItems = markdownFiles
    .map(parseMarkdownFile)
    .filter(item => item !== null)

  console.log(`Generated ${searchItems.length} search items`)

  // Generate TypeScript file
  const tsContent = `// Auto-generated search index - DO NOT EDIT MANUALLY
// Generated by: node scripts/generate-search-index.mjs

export interface SearchItem {
  title: string
  slug: string
  section: "docs" | "vignette"
  lang: "r" | "python"
  locale: string
  content: string
  url: string
}

export const searchData: SearchItem[] = ${JSON.stringify(searchItems, null, 2)}
`

  // Ensure lib directory exists
  const libDir = path.dirname(OUTPUT_FILE)
  if (!fs.existsSync(libDir)) {
    fs.mkdirSync(libDir, { recursive: true })
  }

  fs.writeFileSync(OUTPUT_FILE, tsContent)
  console.log(`Search index written to: ${OUTPUT_FILE}`)

  // Print summary by section
  const bySectionLang = searchItems.reduce((acc, item) => {
    const key = `${item.locale}/${item.section}/${item.lang}`
    acc[key] = (acc[key] || 0) + 1
    return acc
  }, {})

  console.log('\nSummary:')
  Object.entries(bySectionLang).sort().forEach(([key, count]) => {
    console.log(`  ${key}: ${count} pages`)
  })
}

generateSearchIndex()
