---
title: Quality Scoring
---

Quality scoring helps evaluate the reliability of cell type annotations. CASSIA provides automated scoring functionality through the `runCASSIA_score_batch` function, which analyzes the reasoning and evidence behind each annotation.

### Running Quality Scoring

```python
# Run quality scoring
CASSIA.runCASSIA_score_batch(
    input_file = output_name + "_full.csv",
    output_file = output_name + "_scored.csv",
    max_workers = 6,
    model = "openai/gpt-5.1",
    provider = "openrouter",
    generate_report = True,  # Default, generates HTML report automatically
    reasoning = "medium"  # Optional: "low", "medium", "high"
)
```

### Parameter Details

- **`input_file`**: Path to the full annotation results CSV file (generated by `runCASSIA_batch`).
- **`output_file`**: The name for the output scored results CSV file.
- **`max_workers`**: Number of parallel scoring threads.
- **`model`**: The LLM used for quality scoring. High-capability models like `claude-sonnet-4.5` or `gpt-4o` are recommended for accurate scoring.
- **`provider`**: The API provider for the model (e.g., "openrouter").
- **`generate_report`**: Whether to automatically generate an HTML report (default: `True`). The report is saved as `{output_file}_report.html`.
- **`reasoning`**: (Optional) Reasoning effort level ("low", "medium", "high"). Controls how much the model "thinks" before responding. Only supported by OpenAI GPT-5 series models (e.g., `gpt-5.1`). Via OpenRouter, no additional verification needed. Via direct OpenAI API, identity verification (KYC) is required.

### Interpreting Scores

- **90-100**: High confidence, strong evidence.
- **76-89**: Good confidence, adequate evidence.
- **<75**: Low confidence. These clusters are candidates for further analysis using the Annotation Boost Agent or Compare Agent.

An HTML report is automatically generated at `{output_file}_report.html` containing all CASSIA outputs including structured results, conversation histories, and quality scores.
