\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\makeatletter\@ifl@t@r\fmtversion{2018/04/01}{}{\usepackage[utf8]{inputenc}}\makeatother
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `CASSIA'}}
\par\bigskip{\large \today}
\end{center}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdftitle = {CASSIA: Collaborative Agent System for Single-Cell Interpretable Annotation}}}{}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdfauthor = {Elliot Yixuan Xie}}}{}
\begin{description}
\raggedright{}
\item[Title]\AsIs{Collaborative Agent System for Single-Cell Interpretable
Annotation}
\item[Version]\AsIs{0.1.0}
\item[Description]\AsIs{Provides R wrappers for a collaborative agent system designed for
single-cell RNA sequencing cell type annotation. Uses 'reticulate' to interface
with a Python backend that leverages large language models for interpretable
cell type analysis and batch processing of single-cell data.}
\item[License]\AsIs{MIT + file LICENSE}
\item[URL]\AsIs{}\url{https://github.com/ElliotXie/CASSIA}\AsIs{, }\url{https://docs.cassia.bio}\AsIs{}
\item[BugReports]\AsIs{}\url{https://github.com/ElliotXie/CASSIA/issues}\AsIs{}
\item[Encoding]\AsIs{UTF-8}
\item[Roxygen]\AsIs{list(markdown = TRUE)}
\item[RoxygenNote]\AsIs{7.3.2}
\item[Depends]\AsIs{R (>= 3.5.0)}
\item[Imports]\AsIs{reticulate, Seurat}
\item[Suggests]\AsIs{testthat (>= 3.0.0)}
\item[Config/testthat/edition]\AsIs{3}
\item[Config/reticulate]\AsIs{list( conda_env = ``cassia_env'' )}
\item[NeedsCompilation]\AsIs{no}
\item[Author]\AsIs{Elliot Yixuan Xie [aut, cre]}
\item[Maintainer]\AsIs{Elliot Yixuan Xie }\email{xie227@wisc.edu}\AsIs{}
\end{description}
\Rdcontents{Contents}
\HeaderA{.get\_py\_model\_settings}{Get Python CASSIA Module}{.get.Rul.py.Rul.model.Rul.settings}
\keyword{internal}{.get\_py\_model\_settings}
%
\begin{Description}
Get Python CASSIA Module
\end{Description}
%
\begin{Usage}
\begin{verbatim}
.get_py_model_settings()
\end{verbatim}
\end{Usage}
%
\begin{Value}
Python CASSIA module (all functions available at package level)
\end{Value}
\HeaderA{add\_cassia\_to\_seurat}{Add CASSIA Annotations to Seurat Object}{add.Rul.cassia.Rul.to.Rul.seurat}
%
\begin{Description}
This function integrates CASSIA annotation results with a Seurat object by adding
the cell type annotations as metadata columns. The function matches cluster IDs
from CASSIA results to the cluster IDs in the Seurat object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
add_cassia_to_seurat(
  seurat_obj,
  cassia_results_path,
  cluster_col = "seurat_clusters",
  cassia_cluster_col = "Cluster ID",
  prefix = "CASSIA_",
  replace_existing = FALSE,
  fuzzy_match = TRUE,
  columns_to_include = 1
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{seurat\_obj}] A Seurat object

\item[\code{cassia\_results\_path}] Path to the CASSIA output CSV file

\item[\code{cluster\_col}] Name of the column in Seurat metadata containing cluster IDs (default: "seurat\_clusters")

\item[\code{cassia\_cluster\_col}] Name of the column in CASSIA results containing cluster IDs (default: "Cluster ID")

\item[\code{prefix}] Prefix to add to the new metadata columns (default: "CASSIA\_")

\item[\code{replace\_existing}] Whether to replace existing annotations (default: FALSE)

\item[\code{fuzzy\_match}] Whether to perform fuzzy matching on cluster names (default: TRUE)

\item[\code{columns\_to\_include}] Level of columns to include: 1 for only merged groupings, 2 for all metrics (default: 2)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A Seurat object with CASSIA annotations added as metadata columns
\end{Value}
\HeaderA{calculate\_evaluation\_metrics}{Calculate Evaluation Metrics}{calculate.Rul.evaluation.Rul.metrics}
%
\begin{Description}
Calculate comprehensive metrics from evaluation results including mean scores,
distributions, and performance ratios.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
calculate_evaluation_metrics(eval_df, score_col = "score")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{eval\_df}] Data frame containing evaluation results

\item[\code{score\_col}] Character string specifying the column name for evaluation scores (default: "score")
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A named list containing calculated metrics:
\begin{itemize}

\item{} mean\_score: Average score
\item{} median\_score: Median score
\item{} min\_score: Minimum score
\item{} max\_score: Maximum score
\item{} std\_score: Standard deviation of scores
\item{} count: Number of evaluations
\item{} For 0-5 scale: perfect\_ratio, very\_good\_ratio, good\_ratio, partial\_ratio, poor\_ratio, nonsensical\_ratio

\end{itemize}

\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Calculate metrics from evaluation results
metrics <- calculate_evaluation_metrics(
  eval_df = evaluation_results,
  score_col = "evaluation_score"
)

# Print key metrics
cat("Mean Score:", metrics$mean_score, "\n")
cat("Perfect Predictions:", sprintf("%.1f%%", metrics$perfect_ratio * 100), "\n")

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{check\_python\_env}{Check Python Environment}{check.Rul.python.Rul.env}
%
\begin{Description}
Check Python Environment
\end{Description}
%
\begin{Usage}
\begin{verbatim}
check_python_env()
\end{verbatim}
\end{Usage}
%
\begin{Value}
TRUE if the Python environment is set up correctly, FALSE otherwise.
\end{Value}
\HeaderA{compareCelltypes}{Compare Cell Types Using Different Models}{compareCelltypes}
%
\begin{Description}
Compare Cell Types Using Different Models
\end{Description}
%
\begin{Usage}
\begin{verbatim}
compareCelltypes(
  tissue,
  celltypes,
  marker,
  species = "human",
  model_list = NULL,
  output_file = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{tissue}] Character string specifying the tissue type

\item[\code{celltypes}] Character vector of 2-4 cell types to compare

\item[\code{marker}] Character vector or string of marker genes

\item[\code{species}] Character string specifying the species (default: "human")

\item[\code{model\_list}] Character vector of model names to use (optional)

\item[\code{output\_file}] Character string specifying output file path (optional)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list containing responses from different models
\end{Value}
\HeaderA{generate\_html\_report}{Generate HTML Evaluation Report}{generate.Rul.html.Rul.report}
%
\begin{Description}
Generate a comprehensive HTML report for evaluation results with visualizations,
metrics, and sample analyses.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
generate_html_report(
  result_df,
  gold_col,
  pred_col,
  score_col = "score",
  reasoning_col = "reasoning",
  metrics = NULL,
  html_report_path = "report.html",
  model_name = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{result\_df}] Data frame containing the evaluation results

\item[\code{gold\_col}] Character string specifying the column name for ground truth/gold standard values

\item[\code{pred\_col}] Character string specifying the column name for predicted values

\item[\code{score\_col}] Character string specifying the column name for evaluation scores (default: "score")

\item[\code{reasoning\_col}] Character string specifying the column name for reasoning/explanation text (default: "reasoning")

\item[\code{metrics}] Named list of pre-calculated metrics (optional, will be calculated if NULL)

\item[\code{html\_report\_path}] Character string specifying the output path for HTML report (default: "report.html")

\item[\code{model\_name}] Character string specifying the model name to display in the report (optional)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None. This function generates an HTML report file.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Generate evaluation report
generate_html_report(
  result_df = evaluation_results,
  gold_col = "Cluster ID",
  pred_col = "Predicted General Cell Type",
  score_col = "evaluation_score",
  reasoning_col = "explanation",
  html_report_path = "evaluation_report.html",
  model_name = "Claude-3.5-Sonnet"
)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{generate\_subclustering\_report}{Generate Subclustering HTML Report}{generate.Rul.subclustering.Rul.report}
%
\begin{Description}
Generate a beautiful HTML report for subclustering batch results, showing annotation,
reasoning, and top markers in an interactive format.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
generate_subclustering_report(
  csv_path,
  html_report_path = NULL,
  model_name = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{csv\_path}] Character string specifying the path to the subclustering CSV results file

\item[\code{html\_report\_path}] Character string specifying the output path for the HTML report.
If NULL, will use the same name as csv\_path but with .html extension

\item[\code{model\_name}] Character string specifying the model name to display in the report.
If NULL, will extract from the CSV filename
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None. This function generates an HTML report file.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Generate a subclustering report from CSV results
generate_subclustering_report(
  csv_path = "subclustering_results.csv",
  html_report_path = "subclustering_report.html",
  model_name = "Gemini-2.5-Flash"
)

# Auto-generate HTML filename and model name
generate_subclustering_report("subclustering_results.csv")

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{get\_cost\_tier\_models}{Get Cost Tier Models}{get.Rul.cost.Rul.tier.Rul.models}
%
\begin{Description}
Get models in a specific cost tier.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_cost_tier_models(cost_tier)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{cost\_tier}] Character string of the cost tier name
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A character vector of model names
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Get models by cost tier
get_cost_tier_models("very_low")
get_cost_tier_models("low")
get_cost_tier_models("medium")
get_cost_tier_models("high")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{get\_logger}{Get CASSIA Logger}{get.Rul.logger}
%
\begin{Description}
Get or create a CASSIA logger instance for custom logging.
This is primarily for advanced users who want to add custom log messages
that integrate with CASSIA's logging system.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_logger(name = "CASSIA")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{name}] Character string specifying the logger name.
Will be prefixed with "CASSIA." automatically.
Default is "CASSIA" for the root logger.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A Python logging.Logger object
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Get the default CASSIA logger
logger <- get_logger()

# Get a named logger for custom module
my_logger <- get_logger("my_analysis")

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{get\_model\_aliases}{Get Model Aliases}{get.Rul.model.Rul.aliases}
%
\begin{Description}
Get all aliases for a model.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_model_aliases(model_name, provider = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model\_name}] Character string of the model name

\item[\code{provider}] Character string of the provider name (if NULL, will try to infer)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A character vector of aliases
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Get aliases for models
get_model_aliases("gpt-4o")
get_model_aliases("claude-3-5-sonnet-latest")
get_model_aliases("google/gemini-2.5-flash")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{get\_model\_info}{Get Model Information}{get.Rul.model.Rul.info}
%
\begin{Description}
Get detailed information about a model.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_model_info(model_name, provider = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model\_name}] Character string of the model name

\item[\code{provider}] Character string of the provider name (if NULL, will try to infer)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list with model information or NULL if not found
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Get info for specific models
get_model_info("gpt-4o")
get_model_info("claude-3-5-sonnet-latest")
get_model_info("google/gemini-2.5-flash")

# Using aliases
get_model_info("gemini")
get_model_info("deepseek")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{get\_recommended\_model}{Get Recommended Model}{get.Rul.recommended.Rul.model}
%
\begin{Description}
Get the recommended model for a provider or use case.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_recommended_model(provider = NULL, use_case = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{provider}] Character string of the provider name (if NULL, returns overall best model)

\item[\code{use\_case}] Character string of the use case (annotation, scoring, annotation\_boost, merging)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list with two elements: 'model' (recommended model name) and 'provider' (provider name)
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Get overall best model
get_recommended_model()

# Get best model for specific use case
get_recommended_model(use_case = "annotation")
get_recommended_model(use_case = "scoring")
get_recommended_model(use_case = "annotation_boost")

# Get recommended model for specific provider
get_recommended_model(provider = "openai")
get_recommended_model(provider = "anthropic")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{get\_use\_case\_recommendations}{Get Use Case Recommendations}{get.Rul.use.Rul.case.Rul.recommendations}
%
\begin{Description}
Get recommendations for a specific use case.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_use_case_recommendations(use_case)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{use\_case}] Character string of the use case name
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list with recommendations
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Get recommendations for different use cases
get_use_case_recommendations("annotation")
get_use_case_recommendations("scoring")
get_use_case_recommendations("annotation_boost")
get_use_case_recommendations("merging")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{listAvailableMarkers}{List Available Built-in Marker Sets}{listAvailableMarkers}
%
\begin{Description}
This function lists all available built-in marker sets in the CASSIA package.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
listAvailableMarkers()
\end{verbatim}
\end{Usage}
%
\begin{Value}
A character vector containing names of available marker files
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
available_markers <- listAvailableMarkers()
print(available_markers)

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{list\_models}{List Available Models}{list.Rul.models}
%
\begin{Description}
List available models with optional filtering.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
list_models(provider = NULL, cost_tier = NULL, use_case = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{provider}] Character string to filter by provider

\item[\code{cost\_tier}] Character string to filter by cost tier (very\_low, low, medium, high)

\item[\code{use\_case}] Character string to filter by use case
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A data frame with model information
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# List all models
list_models()

# Filter by provider
list_models(provider = "openai")
list_models(provider = "anthropic")
list_models(provider = "openrouter")

# Filter by cost tier
list_models(cost_tier = "low")
list_models(cost_tier = "high")

# Filter by use case
list_models(use_case = "annotation")
list_models(use_case = "scoring")

# Combine filters
list_models(provider = "openrouter", cost_tier = "low")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{loadBuiltinMarkers}{Load Built-in Marker Data}{loadBuiltinMarkers}
%
\begin{Description}
This function loads built-in marker files from the CASSIA package.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
loadBuiltinMarkers(marker_type = "processed")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{marker\_type}] Type of markers to load. Options:
\begin{itemize}

\item{} "processed": For processed marker data (default)
\item{} "unprocessed": For raw unprocessed marker data
\item{} "subcluster\_results": For subcluster analysis results

\end{itemize}

\end{ldescription}
\end{Arguments}
%
\begin{Value}
A data frame containing marker data
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
markers <- loadBuiltinMarkers()
head(markers)

subcluster_results <- loadBuiltinMarkers("subcluster_results")
head(subcluster_results)

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{loadExampleMarkers}{Load Example Marker Data}{loadExampleMarkers}
%
\begin{Description}
This function loads an example marker dataset that can be used to test CASSIA's
cell type annotation functionality. The dataset contains marker genes for
different immune cell types from a PBMC dataset.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
loadExampleMarkers(processed = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{processed}] Logical. If TRUE, loads preprocessed RDS data. If FALSE, loads raw CSV data.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
markers <- loadExampleMarkers()
head(markers)
\end{ExampleCode}
\end{Examples}
\HeaderA{loadExampleMarkers\_subcluster}{Load Example Subcluster Results}{loadExampleMarkers.Rul.subcluster}
%
\begin{Description}
This function loads example subcluster results data that can be used to test CASSIA's
functionality.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
loadExampleMarkers_subcluster()
\end{verbatim}
\end{Usage}
%
\begin{Value}
A data frame containing subcluster results
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
subcluster_data <- loadExampleMarkers_subcluster()
head(subcluster_data)
\end{ExampleCode}
\end{Examples}
\HeaderA{merge\_annotations}{Merge Cell Cluster Annotations}{merge.Rul.annotations}
%
\begin{Description}
Agent function that reads a CSV file with cell cluster annotations and merges/groups them
using an LLM to suggest biologically meaningful groupings.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
merge_annotations(
  csv_path,
  output_path = NULL,
  provider = "openai",
  model = NULL,
  api_key = NULL,
  additional_context = NULL,
  batch_size = 20L,
  detail_level = "broad"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{csv\_path}] Path to the CSV file containing cluster annotations

\item[\code{output\_path}] Path to save the results (if NULL, returns DataFrame without saving)

\item[\code{provider}] LLM provider to use ("openai", "anthropic", or "openrouter") (default: "openai")

\item[\code{model}] Specific model to use (if NULL, uses default for provider)

\item[\code{api\_key}] API key for the provider (if NULL, gets from environment)

\item[\code{additional\_context}] Optional domain-specific context to help with annotation

\item[\code{batch\_size}] Number of clusters to process in each LLM call (default: 20)

\item[\code{detail\_level}] Level of detail for groupings: "broad", "detailed", or "very\_detailed" (default: "broad")
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A data frame with original annotations and suggested cell groupings
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Basic usage - merge annotations with broad groupings
result <- merge_annotations("annotation_results.csv", "merged_results.csv")

# Use detailed groupings
result <- merge_annotations(
  csv_path = "annotation_results.csv",
  output_path = "merged_detailed.csv",
  detail_level = "detailed",
  provider = "anthropic"
)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{merge\_annotations\_all}{Merge All Annotation Levels}{merge.Rul.annotations.Rul.all}
%
\begin{Description}
Process all three detail levels (broad, detailed, very\_detailed) and return a combined DataFrame
with all three grouping columns.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
merge_annotations_all(
  csv_path,
  output_path = NULL,
  provider = "openai",
  model = NULL,
  api_key = NULL,
  additional_context = NULL,
  batch_size = 20L
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{csv\_path}] Path to the CSV file containing cluster annotations

\item[\code{output\_path}] Path to save the results (if NULL, returns DataFrame without saving)

\item[\code{provider}] LLM provider to use ("openai", "anthropic", or "openrouter") (default: "openai")

\item[\code{model}] Specific model to use (if NULL, uses default for provider)

\item[\code{api\_key}] API key for the provider (if NULL, gets from environment)

\item[\code{additional\_context}] Optional domain-specific context to help with annotation

\item[\code{batch\_size}] Number of clusters to process in each LLM call (default: 20)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A data frame with original annotations and all three grouping levels
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Process all grouping levels at once
result <- merge_annotations_all(
  csv_path = "annotation_results.csv",
  output_path = "merged_all_levels.csv",
  provider = "openrouter"
)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{print\_model\_recommendations}{Print Model Recommendations}{print.Rul.model.Rul.recommendations}
%
\begin{Description}
Print model recommendations in a user-friendly format.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
print_model_recommendations(use_case = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{use\_case}] Character string of the specific use case to show recommendations for (optional)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None (prints to console)
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Print all recommendations
print_model_recommendations()

# Print recommendations for specific use case
print_model_recommendations("annotation")
print_model_recommendations("scoring")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{resolve\_model\_name}{Resolve Model Name}{resolve.Rul.model.Rul.name}
%
\begin{Description}
Resolve a user-provided model name to the actual provider model name.
This function automatically maps simplified names (like "gpt4", "claude", "gemini")
to their actual provider-specific names.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
resolve_model_name(model_name, provider = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model\_name}] Character string of the model name (can be alias or actual name)

\item[\code{provider}] Character string of the provider name (if NULL, will try to infer from model\_name)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list with two elements: 'model' (actual model name) and 'provider' (provider name)
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Using simple names
resolve_model_name("gpt4")  # Returns gpt-4o with openai provider
resolve_model_name("claude")  # Returns claude-3-5-sonnet-latest with anthropic provider
resolve_model_name("gemini")  # Returns google/gemini-2.5-flash with openrouter provider

# Using aliases
resolve_model_name("sonnet")  # Returns claude-3-5-sonnet-latest
resolve_model_name("deepseek")  # Returns deepseek/deepseek-chat-v3-0324

# With specific provider
resolve_model_name("gpt-4o", "openai")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{runCASSIA}{Run Cell Type Analysis}{runCASSIA}
%
\begin{Description}
Run Cell Type Analysis
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA(
  model = "google/gemini-2.5-flash-preview",
  temperature,
  marker_list,
  tissue,
  species,
  additional_info = NULL,
  provider = "openrouter",
  validator_involvement = "v1",
  use_reference = FALSE,
  reasoning = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model}] Character string specifying the model to use.

\item[\code{temperature}] Numeric value for temperature parameter.

\item[\code{marker\_list}] List of marker genes. Can be a character vector, comma-separated string, or
a data frame with a 'gene' column.

\item[\code{tissue}] Character string specifying the tissue type.

\item[\code{species}] Character string specifying the species.

\item[\code{additional\_info}] Additional information as a character string.

\item[\code{provider}] AI provider to use ('openai', 'anthropic', or 'openrouter', default='openai')

\item[\code{validator\_involvement}] Validator involvement level: "v0" for high involvement (stronger validation), "v1" for moderate involvement (default: "v1")

\item[\code{use\_reference}] Logical. Whether to use reference-based annotation for complex cases (default: FALSE)

\item[\code{reasoning}] Reasoning effort level: "high", "medium", or "low". Default: NULL (no extended reasoning)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list containing three elements: structured\_output, conversation\_history, and reference\_info.
\end{Value}
\HeaderA{runCASSIA\_annotationboost}{Generate Cell Type Analysis Report}{runCASSIA.Rul.annotationboost}
%
\begin{Description}
Generate Cell Type Analysis Report
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_annotationboost(
  full_result_path,
  marker,
  cluster_name,
  major_cluster_info,
  output_name,
  num_iterations = 5,
  model = "google/gemini-2.5-flash-preview",
  provider = "openrouter",
  temperature = 0,
  conversation_history_mode = "final",
  search_strategy = "breadth",
  report_style = "per_iteration",
  validator_involvement = "v1",
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{full\_result\_path}] Path to the full results CSV file

\item[\code{marker}] Path to the marker genes CSV file or data frame with marker data

\item[\code{cluster\_name}] Name of the cluster to analyze

\item[\code{major\_cluster\_info}] General information about the dataset (e.g., "Human PBMC")

\item[\code{output\_name}] Name of the output HTML file

\item[\code{num\_iterations}] Number of iterations for marker analysis (default=5)

\item[\code{model}] Model to use for analysis (default="google/gemini-2.5-flash-preview")

\item[\code{provider}] AI provider to use ('openai', 'anthropic', or 'openrouter')

\item[\code{temperature}] Sampling temperature (0-1)

\item[\code{conversation\_history\_mode}] Mode for extracting conversation history ("full", "final", or "none")

\item[\code{search\_strategy}] Search strategy - "breadth" (test multiple hypotheses) or "depth" (one hypothesis at a time) (default: "breadth")

\item[\code{report\_style}] Style of report ("per\_iteration" or "total\_summary") (default: "per\_iteration")

\item[\code{validator\_involvement}] Validator involvement level: "v0" for high involvement (stronger validation), "v1" for moderate involvement (default: "v1")

\item[\code{...}] Additional arguments passed to the Python function
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None. This function generates output files.
\end{Value}
\HeaderA{runCASSIA\_annotationboost\_additional\_task}{Generate Cell Type Analysis Report with Additional Task}{runCASSIA.Rul.annotationboost.Rul.additional.Rul.task}
%
\begin{Description}
Generate Cell Type Analysis Report with Additional Task
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_annotationboost_additional_task(
  full_result_path,
  marker,
  cluster_name,
  major_cluster_info,
  output_name,
  num_iterations = 5,
  model = "google/gemini-2.5-flash-preview",
  provider = "openrouter",
  additional_task = "check if this is a cancer cluster",
  temperature = 0,
  conversation_history_mode = "final",
  search_strategy = "breadth",
  report_style = "per_iteration",
  validator_involvement = "v1",
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{full\_result\_path}] Path to the full results CSV file

\item[\code{marker}] Path to the marker genes CSV file or data frame with marker data

\item[\code{cluster\_name}] Name of the cluster to analyze

\item[\code{major\_cluster\_info}] General information about the dataset (e.g., "Human PBMC")

\item[\code{output\_name}] Name of the output HTML file

\item[\code{num\_iterations}] Number of iterations for marker analysis (default=5)

\item[\code{model}] Model to use for analysis (default="google/gemini-2.5-flash-preview")

\item[\code{provider}] AI provider to use ('openai', 'anthropic', or 'openrouter')

\item[\code{additional\_task}] Additional task to perform during analysis

\item[\code{temperature}] Sampling temperature (0-1)

\item[\code{conversation\_history\_mode}] Mode for extracting conversation history ("full", "final", or "none")

\item[\code{search\_strategy}] Search strategy - "breadth" (test multiple hypotheses) or "depth" (one hypothesis at a time) (default: "breadth")

\item[\code{report\_style}] Style of report ("per\_iteration" or "total\_summary") (default: "per\_iteration")

\item[\code{validator\_involvement}] Validator involvement level: "v0" for high involvement (stronger validation), "v1" for moderate involvement (default: "v1")

\item[\code{...}] Additional parameters for future compatibility
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None. This function generates output files.
\end{Value}
\HeaderA{runCASSIA\_batch}{Run Cell Type Analysis Batch}{runCASSIA.Rul.batch}
%
\begin{Description}
Run Cell Type Analysis Batch
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_batch(
  marker,
  output_name = "cell_type_analysis_results.json",
  model = "google/gemini-2.5-flash-preview",
  temperature = 0,
  tissue = "lung",
  species = "human",
  additional_info = NULL,
  celltype_column = NULL,
  gene_column_name = NULL,
  max_workers = 10,
  provider = "openrouter",
  n_genes = 50,
  max_retries = 1,
  validator_involvement = "v1",
  ranking_method = "avg_log2FC",
  ascending = NULL,
  reasoning = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{marker}] A data frame or path to the CSV file containing marker data.

\item[\code{output\_name}] Name of the output JSON file.

\item[\code{model}] Character string specifying the model to use.

\item[\code{temperature}] Numeric value for temperature parameter.

\item[\code{tissue}] Character string specifying the tissue type.

\item[\code{species}] Character string specifying the species.

\item[\code{additional\_info}] Additional information as a character string.

\item[\code{celltype\_column}] Name of the column containing cell types.

\item[\code{gene\_column\_name}] Name of the column containing gene names.

\item[\code{max\_workers}] Maximum number of workers for parallel processing.

\item[\code{provider}] AI provider to use ('openai', 'anthropic', or 'openrouter')

\item[\code{n\_genes}] Number of top genes to use (default: 50)

\item[\code{max\_retries}] Maximum number of retries for failed analyses (default: 1)

\item[\code{validator\_involvement}] Validator involvement level: "v0" for high involvement (stronger validation), "v1" for moderate involvement (default: "v1")

\item[\code{ranking\_method}] Method used to rank marker genes: "avg\_log2FC" (default), "p\_val\_adj", "pct\_diff", or "Score".

\item[\code{ascending}] Logical value indicating sort direction. If NULL (default), uses method-specific default.

\item[\code{reasoning}] Reasoning effort level: "high", "medium", or "low". Default: NULL (no extended reasoning)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None. This function creates output files and prints execution time.
\end{Value}
\HeaderA{runCASSIA\_batch\_n\_times}{Run Batch Analysis Multiple Times}{runCASSIA.Rul.batch.Rul.n.Rul.times}
%
\begin{Description}
Run Batch Analysis Multiple Times
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_batch_n_times(
  n,
  marker,
  output_name = "cell_type_analysis_results",
  model = "google/gemini-2.5-flash-preview",
  temperature = 0,
  tissue = "lung",
  species = "human",
  additional_info = NULL,
  celltype_column = NULL,
  gene_column_name = NULL,
  max_workers = 10,
  batch_max_workers = 5,
  provider = "openrouter",
  max_retries = 1,
  validator_involvement = "v1"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{n}] Number of times to run the batch analysis.

\item[\code{marker}] Path to the CSV file containing marker data.

\item[\code{output\_name}] Prefix for output JSON files.

\item[\code{model}] Character string specifying the model to use.

\item[\code{temperature}] Numeric value for temperature parameter.

\item[\code{tissue}] Character string specifying the tissue type.

\item[\code{species}] Character string specifying the species.

\item[\code{additional\_info}] Additional information as a character string.

\item[\code{celltype\_column}] Name of the column containing cell types.

\item[\code{gene\_column\_name}] Name of the column containing gene names.

\item[\code{max\_workers}] Maximum number of workers for parallel processing.

\item[\code{batch\_max\_workers}] Maximum number of workers for batch processing.

\item[\code{provider}] AI provider to use ('openai', 'anthropic', or 'openrouter')

\item[\code{max\_retries}] Maximum number of retries for failed analyses (default: 1)

\item[\code{validator\_involvement}] Validator involvement level: "v0" for high involvement (stronger validation), "v1" for moderate involvement (default: "v1")
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None. This function creates output files and prints execution time.
\end{Value}
\HeaderA{runCASSIA\_generate\_score\_report}{Generate HTML Reports from Scored Results}{runCASSIA.Rul.generate.Rul.score.Rul.report}
%
\begin{Description}
This function processes a CSV file containing scored annotation results and generates
individual HTML reports for each row, along with an index page.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_generate_score_report(
  csv_path,
  output_name = "CASSIA_reports_summary"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{csv\_path}] Character string. Path to the CSV file containing scored results.

\item[\code{output\_name}] Character string. Base name for the output index file (default: "CASSIA\_reports\_summary").
\end{ldescription}
\end{Arguments}
%
\begin{Details}
The function generates:
\begin{enumerate}

\item{} Individual HTML reports for each annotation result
\item{} An index page linking to all generated reports

\end{enumerate}


The CSV file should contain columns:
\begin{itemize}

\item{} Conversation History
\item{} Scoring\_Reasoning
\item{} Score

\end{itemize}

\end{Details}
%
\begin{Value}
None. Files are written to the current directory.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
runCASSIA_generate_score_report("path/to/scored_results.csv")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{runCASSIA\_merge\_annotations}{Merge Cell Type Annotations using LLM}{runCASSIA.Rul.merge.Rul.annotations}
%
\begin{Description}
This function uses large language models to merge and group single-cell RNA-seq cluster annotations
at different levels of granularity. Results are saved directly to a CSV file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_merge_annotations(
  csv_path,
  output_path = NULL,
  provider = "openrouter",
  model = "deepseek/deepseek-chat-v3-0324",
  additional_context = NULL,
  batch_size = 20,
  detail_level = "broad",
  process_all = FALSE,
  debug = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{csv\_path}] Path to the CSV file containing cluster annotations

\item[\code{output\_path}] Path to save the results (if NULL, saves back to input CSV file)

\item[\code{provider}] LLM provider to use ("openai", "anthropic", or "openrouter")

\item[\code{model}] Specific model to use (if NULL, uses default for provider)

\item[\code{additional\_context}] Optional domain-specific context to help with annotation

\item[\code{batch\_size}] Number of clusters to process in each LLM call

\item[\code{detail\_level}] Level of detail for the groupings: "broad", "detailed", or "very\_detailed"

\item[\code{process\_all}] If TRUE, processes all detail levels sequentially

\item[\code{debug}] If TRUE, print additional debugging information
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Invisibly returns TRUE if successful
\end{Value}
\HeaderA{runCASSIA\_n\_subcluster}{Run Analysis Multiple Times for Subclusters}{runCASSIA.Rul.n.Rul.subcluster}
%
\begin{Description}
Run Analysis Multiple Times for Subclusters
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_n_subcluster(
  n,
  marker,
  major_cluster_info,
  base_output_name,
  model = "google/gemini-2.5-flash-preview",
  temperature = 0,
  provider = "openrouter",
  max_workers = 5,
  n_genes = 50L
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{n}] Number of times to run the analysis

\item[\code{marker}] Marker data (data frame or file path)

\item[\code{major\_cluster\_info}] Description of the major cluster type

\item[\code{base\_output\_name}] Base name for output CSV files

\item[\code{model}] Model name for Claude API (default: "claude-3-5-sonnet-20241022")

\item[\code{temperature}] Temperature parameter for API calls (default: 0)

\item[\code{provider}] AI provider to use (default: "anthropic")

\item[\code{max\_workers}] Maximum number of workers for parallel processing (default: 5)

\item[\code{n\_genes}] Number of top genes to use (default: 50)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None. This function runs the analysis multiple times and saves results to CSV files.
\end{Value}
\HeaderA{runCASSIA\_n\_times}{Run Cell Type Analysis Multiple Times}{runCASSIA.Rul.n.Rul.times}
%
\begin{Description}
Run Cell Type Analysis Multiple Times
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_n_times(
  n,
  tissue,
  species,
  additional_info,
  temperature = 0.3,
  marker_list,
  model = "google/gemini-2.5-flash-preview",
  max_workers = 10,
  provider = "openrouter",
  validator_involvement = "v1",
  use_reference = FALSE,
  reasoning = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{n}] Number of times to run the analysis.

\item[\code{tissue}] Character string specifying the tissue type.

\item[\code{species}] Character string specifying the species.

\item[\code{additional\_info}] Additional information as a character string.

\item[\code{temperature}] Numeric value for temperature parameter. Default: 0.3 (updated to match Python).

\item[\code{marker\_list}] List of marker genes.

\item[\code{model}] Character string specifying the model to use.

\item[\code{max\_workers}] Maximum number of workers for parallel processing.

\item[\code{provider}] AI provider to use ('openai', 'anthropic', or 'openrouter')

\item[\code{validator\_involvement}] Validator involvement level: "v0" for high involvement (stronger validation), "v1" for moderate involvement (default: "v1")

\item[\code{use\_reference}] Logical. Whether to use reference-based annotation for complex cases (default: FALSE)

\item[\code{reasoning}] Reasoning effort level: "high", "medium", or "low". Default: NULL (no extended reasoning)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list containing results from multiple runs, each with analysis\_result, conversation\_history, and reference\_info.
\end{Value}
\HeaderA{runCASSIA\_n\_times\_similarity\_score}{Process Cell Type Analysis Results}{runCASSIA.Rul.n.Rul.times.Rul.similarity.Rul.score}
%
\begin{Description}
Process Cell Type Analysis Results
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_n_times_similarity_score(
  tissue,
  species,
  additional_info,
  temperature,
  marker_list,
  model = "google/gemini-2.5-flash-preview",
  max_workers,
  n,
  provider = "openrouter",
  validator_involvement = "v1",
  use_reference = FALSE,
  generate_report = TRUE,
  report_output_path = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{tissue}] Character string specifying the tissue type.

\item[\code{species}] Character string specifying the species.

\item[\code{additional\_info}] Additional information as a character string.

\item[\code{temperature}] Numeric value for temperature parameter.

\item[\code{marker\_list}] List of marker genes.

\item[\code{model}] Character string specifying the model to use.

\item[\code{max\_workers}] Maximum number of workers for parallel processing.

\item[\code{n}] Number of times to run the analysis.

\item[\code{provider}] AI provider to use ('openai', 'anthropic', or 'openrouter')

\item[\code{validator\_involvement}] Validator involvement level: "v0" for high involvement (stronger validation), "v1" for moderate involvement (default: "v1")

\item[\code{use\_reference}] Logical. Whether to use reference-based annotation for complex cases (default: FALSE)

\item[\code{generate\_report}] Logical. Whether to generate an HTML report (default: TRUE)

\item[\code{report\_output\_path}] Character string. Path to save the HTML report (default: 'uq\_report.html')
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list containing processed results including variance analysis.
\end{Value}
\HeaderA{runCASSIA\_pipeline}{Run Complete Cell Analysis Pipeline}{runCASSIA.Rul.pipeline}
%
\begin{Description}
Run Complete Cell Analysis Pipeline
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_pipeline(
  output_file_name,
  tissue,
  species,
  marker,
  max_workers = 4,
  annotation_model = "google/gemini-2.5-flash",
  annotation_provider = "openrouter",
  score_model = "google/gemini-2.5-flash",
  score_provider = "openrouter",
  annotationboost_model = "google/gemini-2.5-flash",
  annotationboost_provider = "openrouter",
  score_threshold = 75,
  additional_info = NULL,
  max_retries = 1,
  do_merge_annotations = TRUE,
  merge_model = "google/gemini-2.5-flash",
  merge_provider = "openrouter",
  conversation_history_mode = "final",
  search_strategy = "breadth",
  report_style = "per_iteration",
  ranking_method = "avg_log2FC",
  ascending = NULL,
  validator_involvement = "v1",
  output_dir = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{output\_file\_name}] Base name for output files

\item[\code{tissue}] Tissue type being analyzed

\item[\code{species}] Species being analyzed

\item[\code{marker}] Marker data (data frame or file path)

\item[\code{max\_workers}] Maximum number of concurrent workers (default: 4)

\item[\code{annotation\_model}] Model to use for initial annotation (default: "google/gemini-2.5-flash-preview")

\item[\code{annotation\_provider}] Provider for initial annotation (default: "openrouter")

\item[\code{score\_model}] Model to use for scoring (default: "deepseek/deepseek-chat-v3-0324")

\item[\code{score\_provider}] Provider for scoring (default: "openrouter")

\item[\code{annotationboost\_model}] Model to use for boosting low-scoring annotations (default: "google/gemini-2.5-flash-preview")

\item[\code{annotationboost\_provider}] Provider for boosting low-scoring annotations (default: "openrouter")

\item[\code{score\_threshold}] Threshold for identifying low-scoring clusters (default: 75)

\item[\code{additional\_info}] Additional information for analysis (default: NULL)

\item[\code{max\_retries}] Maximum number of retries for failed analyses (default: 1)

\item[\code{do\_merge\_annotations}] Whether to run the merging annotations step (default: TRUE)

\item[\code{merge\_model}] Model to use for merging annotations (default: "deepseek/deepseek-chat-v3-0324")

\item[\code{merge\_provider}] Provider to use for merging annotations (default: "openrouter")

\item[\code{conversation\_history\_mode}] Mode for extracting conversation history ("full", "final", or "none") (default: "final")

\item[\code{search\_strategy}] Search strategy for annotation boost - "breadth" (test multiple hypotheses) or "depth" (one hypothesis at a time) (default: "breadth")

\item[\code{report\_style}] Style of report for annotation boost ("per\_iteration" or "total\_summary") (default: "per\_iteration")

\item[\code{ranking\_method}] Method to rank genes ('avg\_log2FC', 'p\_val\_adj', 'pct\_diff', 'Score') (default: "avg\_log2FC")

\item[\code{ascending}] Sort direction (NULL uses default for each method) (default: NULL)

\item[\code{validator\_involvement}] Validator involvement level: "v0" for high involvement (stronger validation), "v1" for moderate involvement (default: "v1")

\item[\code{output\_dir}] Directory where the output folder will be created. If NULL, uses current working directory. (default: NULL)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None. Creates output files and generates reports.
\end{Value}
\HeaderA{runCASSIA\_score\_batch}{Run Scoring with Progress Updates}{runCASSIA.Rul.score.Rul.batch}
%
\begin{Description}
Run Scoring with Progress Updates
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_score_batch(
  input_file,
  output_file = NULL,
  max_workers = 4,
  model = "deepseek/deepseek-chat-v3-0324",
  provider = "openrouter",
  max_retries = 1
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{input\_file}] Path to input CSV file

\item[\code{output\_file}] Path to output CSV file (optional)

\item[\code{max\_workers}] Maximum number of parallel workers

\item[\code{model}] Model to use

\item[\code{provider}] AI provider to use ('openai', 'anthropic', or 'openrouter')

\item[\code{max\_retries}] Maximum number of retries for failed analyses (default: 1)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None
\end{Value}
\HeaderA{runCASSIA\_similarity\_score\_batch}{Process and Save Batch Results}{runCASSIA.Rul.similarity.Rul.score.Rul.batch}
%
\begin{Description}
Process and Save Batch Results
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_similarity_score_batch(
  marker,
  file_pattern,
  output_name,
  celltype_column = NULL,
  max_workers = 10,
  model = "google/gemini-2.5-flash-preview",
  provider = "openrouter",
  main_weight = 0.5,
  sub_weight = 0.5,
  generate_report = TRUE,
  report_output_path = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{marker}] Path to the marker file.

\item[\code{file\_pattern}] Pattern to match result files.

\item[\code{output\_name}] Name of the output CSV file.

\item[\code{celltype\_column}] Name of the column containing cell types.

\item[\code{max\_workers}] Maximum number of workers for parallel processing.

\item[\code{model}] Model to use for processing (default: "gpt-4o")

\item[\code{provider}] AI provider to use ('openai', 'anthropic', or 'openrouter')

\item[\code{main\_weight}] Weight for the main cell type.

\item[\code{sub\_weight}] Weight for the sub cell type.

\item[\code{generate\_report}] Logical. Whether to generate an HTML report (default: TRUE)

\item[\code{report\_output\_path}] Character string. Path to save the HTML report (default: 'uq\_batch\_report.html')
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None. This function processes and saves results to a CSV file and prints execution time.
\end{Value}
\HeaderA{runCASSIA\_subclusters}{Process Subclusters}{runCASSIA.Rul.subclusters}
%
\begin{Description}
Process Subclusters
\end{Description}
%
\begin{Usage}
\begin{verbatim}
runCASSIA_subclusters(
  marker,
  major_cluster_info,
  output_name,
  model = "google/gemini-2.5-flash-preview",
  temperature = 0,
  provider = "openrouter",
  n_genes = 50L
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{marker}] Marker data (data frame or file path)

\item[\code{major\_cluster\_info}] Description of the major cluster type

\item[\code{output\_name}] Base name for the output file (will add .csv if not present)

\item[\code{model}] Model name for Claude API (default: "claude-3-5-sonnet-20241022")

\item[\code{temperature}] Temperature parameter for API calls (default: 0)

\item[\code{provider}] AI provider to use (default: "anthropic")

\item[\code{n\_genes}] Number of top genes to use (default: 50)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
None. This function processes subclusters and saves results to a CSV file.
\end{Value}
\HeaderA{setAnthropicApiKey}{Set Anthropic API Key}{setAnthropicApiKey}
%
\begin{Description}
Set Anthropic API Key
\end{Description}
%
\begin{Usage}
\begin{verbatim}
setAnthropicApiKey(api_key, persist = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{api\_key}] Character string containing the Anthropic API key

\item[\code{persist}] Logical indicating whether to save the key to .Renviron (default: FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Invisible NULL. Called for side effects.
\end{Value}
\HeaderA{setLLMApiKey}{Set API Key for LLM Provider}{setLLMApiKey}
%
\begin{Description}
Set API Key for LLM Provider
\end{Description}
%
\begin{Usage}
\begin{verbatim}
setLLMApiKey(api_key, provider = "anthropic", persist = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{api\_key}] Character string containing the API key

\item[\code{provider}] Character string specifying the provider ('openai', 'anthropic', or 'openrouter')

\item[\code{persist}] Logical indicating whether to save the key to .Renviron (default: FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Invisible NULL. Called for side effects.
\end{Value}
\HeaderA{setOpenRouterApiKey}{Set OpenRouter API Key}{setOpenRouterApiKey}
%
\begin{Description}
Set OpenRouter API Key
\end{Description}
%
\begin{Usage}
\begin{verbatim}
setOpenRouterApiKey(api_key, persist = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{api\_key}] Character string containing the OpenRouter API key

\item[\code{persist}] Logical indicating whether to save the key to .Renviron (default: FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Invisible NULL. Called for side effects.
\end{Value}
\HeaderA{setup\_cassia\_env}{Set up CASSIA Python Environment}{setup.Rul.cassia.Rul.env}
%
\begin{Description}
This function sets up the required Python environment for CASSIA.
It can be used to create a new environment or update an existing one.
By default, it tries virtualenv first (simpler, more reliable), then falls back to conda.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
setup_cassia_env(
  conda_env = NULL,
  python_version = "3.10",
  pip_packages = c("openai", "pandas", "numpy", "requests", "anthropic", "matplotlib",
    "seaborn"),
  method = "auto"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{conda\_env}] The name of the environment to use. If NULL, uses the default from package configuration.

\item[\code{python\_version}] The Python version to use. Default is "3.10".

\item[\code{pip\_packages}] A character vector of pip packages to install.

\item[\code{method}] The method to use for environment setup. Options: "auto" (try virtualenv first, then conda), "virtualenv", "conda". Default is "auto".
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Invisible NULL. Called for side effects.
\end{Value}
\HeaderA{set\_log\_level}{Set CASSIA Log Level}{set.Rul.log.Rul.level}
%
\begin{Description}
Control the verbosity of CASSIA error and warning messages.
By default, CASSIA shows informational messages, warnings, and errors.
Use this function to adjust the level of detail in log output.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
set_log_level(level = "INFO")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{level}] Character string specifying the log level. One of:
\begin{itemize}

\item{} "DEBUG" - Show all messages including detailed debug info
\item{} "INFO" - Show informational messages, warnings, and errors (default)
\item{} "WARNING" - Show only warnings and errors
\item{} "ERROR" - Show only errors
\item{} "QUIET" - Suppress almost all messages

\end{itemize}

\end{ldescription}
\end{Arguments}
%
\begin{Value}
Invisible NULL. Called for side effects.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Enable verbose debugging
set_log_level("DEBUG")

# Show only errors (quiet mode)
set_log_level("ERROR")

# Suppress all messages
set_log_level("QUIET")

# Reset to default
set_log_level("INFO")

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{set\_openai\_api\_key}{Set OpenAI API Key}{set.Rul.openai.Rul.api.Rul.key}
%
\begin{Description}
Set OpenAI API Key
\end{Description}
%
\begin{Usage}
\begin{verbatim}
set_openai_api_key(api_key, persist = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{api\_key}] Character string containing the OpenAI API key

\item[\code{persist}] Logical indicating whether to save the key to .Renviron (default: FALSE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Invisible NULL. Called for side effects.
\end{Value}
\HeaderA{set\_python\_env}{Set Python Environment}{set.Rul.python.Rul.env}
%
\begin{Description}
Set Python Environment
\end{Description}
%
\begin{Usage}
\begin{verbatim}
set_python_env(conda_env)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{conda\_env}] The name of the environment to use (works with both conda and virtualenv).
\end{ldescription}
\end{Arguments}
%
\begin{Value}
TRUE if the Python environment is set successfully, FALSE otherwise.
\end{Value}
\HeaderA{symphonyCompare}{Symphony Compare - Advanced Multi-Model Cell Type Comparison with Consensus Building}{symphonyCompare}
%
\begin{Description}
Orchestrate multiple AI models to compare cell types with automatic consensus building.
This function conducts a comprehensive cell type comparison using multiple AI models in parallel,
automatically triggering discussion rounds when models disagree on the best matching cell type.
Think of it as a virtual panel of expert biologists debating and reaching consensus.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
symphonyCompare(
  tissue,
  celltypes,
  marker_set,
  species = "human",
  model_preset = "symphony",
  custom_models = NULL,
  output_dir = NULL,
  output_basename = NULL,
  enable_discussion = TRUE,
  max_discussion_rounds = 2L,
  consensus_threshold = 0.8,
  generate_report = TRUE,
  api_key = NULL,
  verbose = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{tissue}] Character string specifying the tissue type (e.g., "blood", "brain", "liver")

\item[\code{celltypes}] Character vector of 2-4 cell types to compare

\item[\code{marker\_set}] Character vector or string of gene markers to analyze

\item[\code{species}] Character string specifying the species (default: "human")

\item[\code{model\_preset}] Character string specifying preset model configuration. Options:
\begin{itemize}

\item{} "symphony": High-performance ensemble (Claude, GPT-4, Gemini Pro)
\item{} "quartet": Balanced 4-model ensemble
\item{} "budget": Cost-effective models
\item{} "custom": Use custom\_models list

\end{itemize}


\item[\code{custom\_models}] Character vector of custom models to use (when model\_preset="custom")

\item[\code{output\_dir}] Character string specifying directory to save results (default: current directory)

\item[\code{output\_basename}] Character string for base name of output files (auto-generated if NULL)

\item[\code{enable\_discussion}] Logical indicating whether to enable automatic discussion rounds when no consensus (default: TRUE)

\item[\code{max\_discussion\_rounds}] Integer specifying maximum discussion rounds to perform (default: 2)

\item[\code{consensus\_threshold}] Numeric value (0-1) specifying fraction of models that must agree for consensus (default: 0.8)

\item[\code{generate\_report}] Logical indicating whether to generate interactive HTML report (default: TRUE)

\item[\code{api\_key}] Character string for OpenRouter API key (uses environment variable if NULL)

\item[\code{verbose}] Logical indicating whether to print progress messages (default: TRUE)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list containing:
\begin{itemize}

\item{} results: List of all model responses and scores
\item{} consensus: The consensus cell type (if reached)
\item{} confidence: Confidence level of the consensus (0-1)
\item{} csv\_file: Path to the generated CSV file
\item{} html\_file: Path to the generated HTML report (if enabled)
\item{} summary: Summary statistics of the comparison
\item{} dataframe: R data frame with structured results

\end{itemize}

\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
# Basic usage - let Symphony Compare handle everything
results <- symphonyCompare(
  tissue = "peripheral blood",
  celltypes = c("T cell", "B cell", "NK cell", "Monocyte"),
  marker_set = c("CD3", "CD4", "CD8", "CD19", "CD20", "CD16", "CD56", "CD14"),
  species = "human"
)

# Access the results
cat("Consensus:", results$consensus, "\n")
cat("Confidence:", sprintf("%.1f%%", results$confidence * 100), "\n")

# Advanced usage with custom settings
results <- symphonyCompare(
  tissue = "brain",
  celltypes = c("Neuron", "Astrocyte", "Microglia", "Oligodendrocyte"),
  marker_set = c("RBFOX3", "GFAP", "IBA1", "OLIG2", "MAP2", "S100B", "CD11B", "MBP"),
  species = "mouse",
  model_preset = "quartet",  # Use 4 models instead of 3
  enable_discussion = TRUE,  # Enable automatic discussion rounds
  max_discussion_rounds = 3,  # Allow up to 3 discussion rounds
  consensus_threshold = 0.75,  # 75% of models must agree
  output_dir = "./symphony_results",
  verbose = TRUE
)

## End(Not run)

\end{ExampleCode}
\end{Examples}
\HeaderA{warn\_user}{Show a Warning to the User}{warn.Rul.user}
%
\begin{Description}
Display a warning message that is always visible, regardless of log level.
Uses Python's warnings module to ensure visibility.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
warn_user(message)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{message}] Character string containing the warning message to display.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Invisible NULL. Called for side effects.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
warn_user("This operation may take a long time with large datasets.")

## End(Not run)

\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
