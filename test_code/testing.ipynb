{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (0.34.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from anthropic) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from anthropic) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from anthropic) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from anthropic) (2.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from anthropic) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from anthropic) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (3.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
      "Requirement already satisfied: certifi in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (2.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from tokenizers>=0.13.0->anthropic) (0.24.6)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.5)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\envs\\pyautogen\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS: Specified value was saved.\n"
     ]
    }
   ],
   "source": [
    "!setx ANTHROPIC_API_KEY \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS: Specified value was saved.\n",
      "[TextBlock(text=\"Waves crash and foam,\\nEarth's tears flow to sea,\\nEons of minerals\\nDissolved endlessly.\\n\\nSalt from ancient rocks,\\nCarried by rivers' might,\\nConcentrates in blue depths,\\nA briny appetite.\", type='text')]\n"
     ]
    }
   ],
   "source": [
    "!setx ANTHROPIC_API_KEY \"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\"\n",
    "\n",
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    system=\"You are a world-class poet. Respond only with short poems.\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Why is the ocean salty?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Waves crash and foam,\\nEarth's tears flow to sea,\\nEons of minerals\\nDissolved endlessly.\\n\\nSalt from ancient rocks,\\nCarried by rivers' might,\\nConcentrates in blue depths,\\nA briny appetite.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting onboarding process...\n",
      "\n",
      "Onboarding Assistant: Great! Let's get started. \n",
      "\n",
      "What is the species of the data?\n",
      "\n",
      "User: \n",
      "\n",
      "Onboarding Assistant: Could you please tell me the species of the data?\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 241\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting onboarding process...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 241\u001b[0m     onboarding_conversation \u001b[38;5;241m=\u001b[39m \u001b[43monboarding_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43monboarding_agent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m     extracted_data \u001b[38;5;241m=\u001b[39m extract_json_from_reply(onboarding_conversation[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    243\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m construct_prompt(extracted_data)\n",
      "Cell \u001b[1;32mIn[1], line 78\u001b[0m, in \u001b[0;36monboarding_process\u001b[1;34m(agent)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONBOARDING COMPLETED\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     80\u001b[0m conversation\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_input))\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pyautogen\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pyautogen\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, system=\"\", human_input_mode=\"never\", ai_provider=\"anthropic\", model=\"claude-3-5-sonnet-20240620\", temperature=0, max_tokens= 1000):\n",
    "        self.system = system\n",
    "        self.chat_histories = {}\n",
    "        self.human_input_mode = human_input_mode\n",
    "        self.ai_provider = ai_provider.lower()\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def __call__(self, message, other_agent_id):\n",
    "        if other_agent_id not in self.chat_histories:\n",
    "            self.chat_histories[other_agent_id] = []\n",
    "            if self.system:\n",
    "                self.chat_histories[other_agent_id].append({\"role\": \"system\", \"content\": self.system})\n",
    "        \n",
    "        self.chat_histories[other_agent_id].append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        result = self.execute(other_agent_id)\n",
    "        self.chat_histories[other_agent_id].append({\"role\": \"assistant\", \"content\": result})\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def execute(self, other_agent_id):\n",
    "        if self.ai_provider == \"anthropic\":\n",
    "            # Use Claude AI\n",
    "            client_anthropic = anthropic.Anthropic()\n",
    "            \n",
    "            # Prepare messages for Claude (excluding system message)\n",
    "            claude_messages = []\n",
    "            for msg in self.chat_histories[other_agent_id]:\n",
    "                if msg[\"role\"] != \"system\":\n",
    "                    claude_messages.append({\n",
    "                        \"role\": msg[\"role\"],\n",
    "                        \"content\": [{\"type\": \"text\", \"text\": msg[\"content\"]}]\n",
    "                    })\n",
    "            \n",
    "            response = client_anthropic.messages.create(\n",
    "                model=self.model,\n",
    "                max_tokens=self.max_tokens,\n",
    "                temperature=self.temperature,\n",
    "                system=self.system,  # System message as a separate parameter\n",
    "                messages=claude_messages\n",
    "            )\n",
    "            return response.content[0].text\n",
    "        else:\n",
    "            # Use OpenAI\n",
    "            completion = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=self.max_tokens,\n",
    "                messages=self.chat_histories[other_agent_id]\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "\n",
    "    def needs_human_input(self, message):\n",
    "        return self.human_input_mode == \"always\"\n",
    "\n",
    "def onboarding_process(agent):\n",
    "    current_message = \"I am your helpful assistant. I will ask you some questions about your single cell analysis so that your analysis can be more accurate.\"\n",
    "    conversation = []\n",
    "    \n",
    "    while True:\n",
    "        response = agent(current_message, \"user\")\n",
    "        print(f\"Onboarding Assistant: {response}\\n\", flush=True)\n",
    "        conversation.append((\"Onboarding Assistant\", response))\n",
    "        \n",
    "        if \"ONBOARDING COMPLETED\" in response:\n",
    "            break\n",
    "        \n",
    "        user_input = input(\"User: \")\n",
    "        print(f\"User: {user_input}\\n\", flush=True)\n",
    "        conversation.append((\"User\", user_input))\n",
    "        current_message = user_input\n",
    "    \n",
    "    print(\"Onboarding Conversation:\")\n",
    "    for role, message in conversation:\n",
    "        print(f\"{role}: {message}\\n\")\n",
    "    \n",
    "    return conversation\n",
    "\n",
    "def extract_json_from_reply(reply):\n",
    "    json_match = re.search(r'```json\\n(.*?)\\n```', reply, re.DOTALL)\n",
    "    \n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "        try:\n",
    "            json_data = json.loads(json_str)\n",
    "            return json_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"No JSON content found in the reply\")\n",
    "        return None\n",
    "\n",
    "def construct_prompt(json_data):\n",
    "    species = json_data['species']\n",
    "    tissue = json_data['tissue_type']\n",
    "    additional_info = json_data.get('additional_info', '')\n",
    "    marker_list = ', '.join(json_data['marker_list'])\n",
    "\n",
    "    prompt = f\"I am analyzing a single-cell {species} {tissue} dataset.\"\n",
    "    if additional_info:\n",
    "        prompt += f\" {additional_info}.\"\n",
    "    prompt += f\" I want to identify the cell types present based on this marker list:\\n{marker_list}\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def final_annotation(agent, prompt):\n",
    "    current_message = prompt\n",
    "    conversation = []\n",
    "    \n",
    "    while True:\n",
    "        response = agent(current_message, \"user\")\n",
    "        print(f\"Final Annotation Agent: {response}\\n\", flush=True)\n",
    "        conversation.append((\"Final Annotation Agent\", response))\n",
    "        \n",
    "        if \"FINAL ANNOTATION COMPLETED\" in response:\n",
    "            break\n",
    "        \n",
    "        if agent.needs_human_input(response):\n",
    "            user_input = input(\"User: \")\n",
    "            print(f\"User: {user_input}\\n\", flush=True)\n",
    "            conversation.append((\"User\", user_input))\n",
    "            current_message = user_input\n",
    "        else:\n",
    "            current_message = response\n",
    "\n",
    "    print(\"Final Annotation Conversation:\")\n",
    "    for role, message in conversation:\n",
    "        print(f\"{role}: {message}\\n\")\n",
    "\n",
    "    return conversation\n",
    "\n",
    "def coupling_validation(agent, annotation_result, onboarding_data):\n",
    "    validation_message = f\"\"\"Please validate the following annotation result:\n",
    "\n",
    "Annotation Result:\n",
    "{annotation_result}\n",
    "\n",
    "Context from onboarding:\n",
    "Species: {onboarding_data['species']}\n",
    "Tissue Type: {onboarding_data['tissue_type']}\n",
    "Marker List: {', '.join(onboarding_data['marker_list'])}\n",
    "Additional Info: {onboarding_data.get('additional_info', 'None')}\n",
    "\n",
    "Validate the annotation based on this context.\n",
    "\"\"\"\n",
    "    response = agent(validation_message, \"final_annotation\")\n",
    "    print(f\"Coupling Validator: {response}\\n\", flush=True)\n",
    "    return response\n",
    "\n",
    "def format_results(agent, final_annotations):\n",
    "    final_text = \"\\n\\n\".join([msg[1] for msg in final_annotations])\n",
    "    return agent(final_text, \"user\")\n",
    "\n",
    "# Define agents\n",
    "onboarding_agent = Agent(system='''You are a friendly onboarding assistant helping to create an initial prompt for analyzing single-cell data.\n",
    "Ask the user questions to gather necessary information. Be concise and friendly in your interactions. \n",
    "Ask one question at a time. If the user provides a confusing answer, kindly ask for clarification.\n",
    "\n",
    "1. What is the species of the data?\n",
    "2. What is the tissue type of the data?\n",
    "3. Please provide the marker list for the analysis.\n",
    "4. Any other information you need to know?\n",
    "\n",
    "When you're done gathering information, say \"ONBOARDING COMPLETED\" followed by a JSON-formatted summary of the collected information.Name each item by species, tissue_type, marker_list, additional_information\n",
    "wrap it with ```json and ```\n",
    "'''.strip(), human_input_mode=\"always\",\n",
    "    ai_provider=\"openai\",\n",
    "    model=\"gpt-4o\")\n",
    "\n",
    "final_annotation_agent = Agent(system=\"\"\"\n",
    "You are a professional computational biologist with expertise in single-cell RNA sequencing (scRNA-seq). I will provide you with a list of markers from a cluster of cells in the mouse larynx, and your task is to identify the cell type. You must think step-by-step, providing a comprehensive and specific analysis. The audience is an expert in the field, and I will tip you $1000 if you do a good job.\n",
    "\n",
    "**Steps to Follow:**\n",
    "\n",
    "1. **List the Key Functional Markers**: Extract and **group** the key marker genes associated with function or pathway, explaining their roles. Do not repeat the input markers.\n",
    "2. **List the Key Cell Type Markers**: Extract and **group** the key marker genes associated with mouse larynx cell types, explaining their roles. Do not repeat the input markers.\n",
    "3. **Cross-reference Known Databases**: Use available scRNA-seq databases and relevant literature to cross-reference these markers. list your finding.\n",
    "4. **Determine the Most Probable General Cell Type**: Based on the expression of these markers, infer the most likely general cell type of the cluster.\n",
    "5. **Identify the Top 3 Most Probable Sub Cell Types**: Based on the expression of these markers, infer the top three most probable sub cell types within the general cell type. Finally, specify the most likely subtype.\n",
    "6. **Identify the Most Probable Sub-Sub Cell Type**: Determine the most specific cell type within the previously identified subtype.\n",
    "7.  **Provide a Concise Summary of Your Analysis:**\n",
    "\n",
    "Always include your step-by-step detailed reasoning.                      \n",
    "Ask for human input.\n",
    "You can say \"FINAL ANNOTATION COMPLETED\" only when the human says good.\n",
    "\n",
    "If you receive feedback from the validation process, incorporate it into your analysis and provide an updated annotation.\n",
    "\"\"\",human_input_mode=\"always\",\n",
    "    ai_provider=\"openai\",\n",
    "    model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "coupling_validator_agent = Agent(system=\"\"\"\n",
    "You are a coupling validator for single-cell analysis results. Your task is to validate the final annotation results.\n",
    "You will be provided with the annotation result and the context from the onboarding process.\n",
    "Please check for the following:\n",
    "\n",
    "1. Consistency between the identified cell type and the provided markers.\n",
    "2. Alignment of the sub-cell types with the main cell type.\n",
    "3. Appropriateness of the annotation given the species and tissue type.\n",
    "4. Proper consideration of the additional information provided during onboarding.\n",
    "\n",
    "Provide your validation result, highlighting any inconsistencies or areas of concern.\n",
    "If everything looks good, say \"VALIDATION PASSED\". Otherwise, say \"VALIDATION FAILED\" and explain why.\n",
    "Be specific in your feedback so that the final annotation agent can address the issues.\n",
    "\"\"\",    ai_provider=\"openai\",\n",
    "    model=\"gpt-4o\")\n",
    "\n",
    "formatting_agent = Agent(system=\"\"\"\n",
    "You are a formatting assistant for single-cell analysis results. Your task is to convert the final integrated results \n",
    "into a structured JSON format. Follow these guidelines:\n",
    "\n",
    "1. Extract the main cell type and any sub-cell types identified.\n",
    "2. Include only information explicitly stated in the input.\n",
    "3. Ensure the output is valid JSON.\n",
    "\n",
    "Provide the JSON output within triple backticks, like this:\n",
    "```json\n",
    "{\n",
    "\"main_cell_type\": \"...\",\n",
    "\"sub_cell_types\": [\"...\", \"...\"]\n",
    "}\n",
    "```\n",
    "\"\"\".strip(), ai_provider=\"openai\",\n",
    "    model=\"gpt-4o\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting onboarding process...\\n\")\n",
    "    onboarding_conversation = onboarding_process(onboarding_agent)\n",
    "    extracted_data = extract_json_from_reply(onboarding_conversation[-1][1])\n",
    "    prompt = construct_prompt(extracted_data)\n",
    "\n",
    "    validation_passed = False\n",
    "    iteration = 0\n",
    "    max_iterations = 3  # Set a maximum number of iterations to prevent infinite loops\n",
    "\n",
    "    while not validation_passed and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        print(f\"\\nStarting final annotation (Iteration {iteration})...\\n\")\n",
    "        final_annotation_conversation = final_annotation(final_annotation_agent, prompt)\n",
    "\n",
    "        print(\"Validating annotation...\\n\")\n",
    "        validation_result = coupling_validation(coupling_validator_agent, final_annotation_conversation[-1][1], extracted_data)\n",
    "\n",
    "        if \"VALIDATION PASSED\" in validation_result:\n",
    "            validation_passed = True\n",
    "        else:\n",
    "            print(\"Validation failed. Sending feedback to the final annotation agent.\\n\")\n",
    "            prompt = f\"Previous annotation attempt failed validation. Please address the following feedback and provide an updated annotation:\\n\\n{validation_result}\\n\\nOriginal prompt: {prompt}\"\n",
    "\n",
    "        print(\"\\nValidation Conversation:\")\n",
    "        print(f\"Final Annotation Agent: {final_annotation_conversation[-1][1]}\\n\")\n",
    "        print(f\"Coupling Validator: {validation_result}\\n\")\n",
    "\n",
    "    if validation_passed:\n",
    "        print(\"Formatting final results...\\n\")\n",
    "        formatted_output = format_results(formatting_agent, final_annotation_conversation[-2:])\n",
    "        structured_output = extract_json_from_reply(formatted_output)\n",
    "        \n",
    "        if structured_output:\n",
    "            print(\"\\nStructured output:\")\n",
    "            print(json.dumps(structured_output, indent=2))\n",
    "        else:\n",
    "            print(\"Error: Unable to extract JSON from the formatted output.\")\n",
    "            print(\"Raw formatted output:\")\n",
    "            print(formatted_output)\n",
    "    else:\n",
    "        print(f\"Validation failed after {max_iterations} attempts. Please review the annotation results and validation feedback.\")\n",
    "\n",
    "    print(\"Analysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis process...\n",
      "\n",
      "Performing final annotation...\n",
      "\n",
      "Formatting final results...\n",
      "\n",
      "\n",
      "Structured output:\n",
      "```\n",
      "{\n",
      "  \"KeyFunctionalMarkers\": {\n",
      "    \"KeratinFamily\": [\"Krt5\", \"Krt14\", \"Krt8\", \"Krt18\"],\n",
      "    \"Trp63\": \"Transcription factor involved in epithelial development and differentiation\",\n",
      "    \"Cadherins\": [\"Cdh1\", \"Cdh2\"],\n",
      "    \"Epcam\": \"Cell surface protein involved in cell adhesion, migration, and proliferation\",\n",
      "    \"Vim\": \"Type III intermediate filament protein expressed in mesenchymal cells\",\n",
      "    \"Acta2\": \"Gene encoding alpha smooth muscle actin protein\",\n",
      "    \"Msln\": \"Gene encoding precursor protein involved in cell adhesion and potentially cancer\",\n",
      "    \"Upk3b\": \"Gene encoding a member of the uroplakin family\",\n",
      "    \"Foxj1\": \"Gene encoding a member of the forkhead family of transcription factors\",\n",
      "    \"Tubb4b\": \"Gene encoding a member of the beta tubulin family\",\n",
      "    \"SecretoglobinFamily\": [\"Scgb1a1\", \"Scgb3a2\"],\n",
      "    \"Mucins\": [\"Muc5ac\", \"Muc5b\"],\n",
      "    \"Ltf\": \"Gene encoding lactoferrin, an iron-binding protein with antibacterial, antifungal, and antiviral activity\"\n",
      "  },\n",
      "  \"KeyCellTypeMarkers\": {\n",
      "    \"BasalCells\": [\"Krt5\", \"Trp63\", \"Krt14\"],\n",
      "    \"CiliatedCells\": [\"Foxj1\", \"Tubb4b\"],\n",
      "    \"SecretoryCells\": [\"Scgb1a1\", \"Scgb3a2\", \"Muc5ac\", \"Muc5b\", \"Ltf\"],\n",
      "    \"MesenchymalCells\": [\"Vim\", \"Acta2\"]\n",
      "  },\n",
      "  \"CrossReferenceDatabases\": [\"Mouse Cell Atlas\"],\n",
      "  \"MostProbableGeneralCellType\": \"Epithelial cells\",\n",
      "  \"Top3MostProbableSubCellTypes\": [\"Basal cells\", \"Ciliated cells\", \"Secretory cells\"],\n",
      "  \"MostProbableSubSubCellType\": \"Basal progenitor cells\",\n",
      "  \"Summary\": \"The cluster of cells from the mouse larynx is most likely composed of epithelial cells, specifically basal progenitor cells. This conclusion is based on the expression of key functional and cell type markers, including Krt5, Trp63, Krt14, and others. These cells have the potential to differentiate into various epithelial cell types, including ciliated and secretory cells.\"\n",
      "}\n",
      "```\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, system=\"\", model=\"gpt-4\", temperature=0):\n",
    "        self.system = system\n",
    "        self.chat_histories = {}\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, message, other_agent_id):\n",
    "        if other_agent_id not in self.chat_histories:\n",
    "            self.chat_histories[other_agent_id] = []\n",
    "            if self.system:\n",
    "                self.chat_histories[other_agent_id].append({\"role\": \"system\", \"content\": self.system})\n",
    "        \n",
    "        self.chat_histories[other_agent_id].append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        result = self.execute(other_agent_id)\n",
    "        self.chat_histories[other_agent_id].append({\"role\": \"assistant\", \"content\": result})\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def execute(self, other_agent_id):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            temperature=self.temperature,\n",
    "            messages=self.chat_histories[other_agent_id]\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "def construct_prompt(species, tissue_type, marker_list, additional_info=\"\"):\n",
    "    markers = ', '.join(marker_list)\n",
    "    prompt = f\"I am analyzing a single-cell {species} {tissue_type} dataset.\"\n",
    "    if additional_info:\n",
    "        prompt += f\" {additional_info}.\"\n",
    "    prompt += f\" I want to identify the cell types present based on this marker list:\\n{markers}\"\n",
    "    return prompt\n",
    "\n",
    "# Define agents\n",
    "final_annotation_agent = Agent(system=\"\"\"\n",
    "Objective:\n",
    "\n",
    "You are a professional computational biologist with expertise in single-cell RNA sequencing (scRNA-seq). I will provide you with a list of markers from a cluster of cells in the mouse larynx, and your task is to identify the cell type. You must think step-by-step, providing a comprehensive and specific analysis. The audience is an expert in the field, and I will tip you $1000 if you do a good job.\n",
    "\n",
    "Steps to Follow:\n",
    "\n",
    "1. List the Key Functional Markers: Extract and group the key marker genes associated with function or pathway, explaining their roles. Do not repeat the input markers.\n",
    "2. List the Key Cell Type Markers: Extract and group the key marker genes associated with mouse larynx cell types, explaining their roles. Do not repeat the input markers.\n",
    "3. Cross-reference Known Databases: Use available scRNA-seq databases and relevant literature to cross-reference these markers. list your finding.\n",
    "4. Determine the Most Probable General Cell Type: Based on the expression of these markers, infer the most likely general cell type of the cluster.\n",
    "5. Identify the Top 3 Most Probable Sub Cell Types: Based on the expression of these markers, infer the top three most probable sub cell types within the general cell type. Finally, specify the most likely subtype.\n",
    "6. Identify the Most Probable Sub-Sub Cell Type: Determine the most specific cell type within the previously identified subtype.\n",
    "7.  Provide a Concise Summary of Your Analysis\n",
    "\"\"\".strip())\n",
    "\n",
    "formatting_agent = Agent(system=\"\"\"\n",
    "You are a formatting assistant for single-cell analysis results. Convert the final integrated results \n",
    "into a structured JSON format. Don't need to extract marker related information.\n",
    "                         \n",
    "1. Extract the main cell type Identified\n",
    "2. Extract sub-cell types identified.\n",
    "\n",
    "Provide the JSON output within triple backticks.\n",
    "\"\"\".strip())\n",
    "\n",
    "def run_analysis(species, tissue_type, marker_list, additional_info=\"\"):\n",
    "    print(\"Starting analysis process...\\n\")\n",
    "    prompt = construct_prompt(species, tissue_type, marker_list, additional_info)\n",
    "\n",
    "    print(\"Performing final annotation...\\n\")\n",
    "    annotation_result = final_annotation_agent(prompt, \"user\")\n",
    "    print(annotation_result)\n",
    "    print(\"Formatting final results...\\n\")\n",
    "    formatted_output = formatting_agent(annotation_result, \"user\")\n",
    "    \n",
    "    print(\"\\nStructured output:\")\n",
    "    print(formatted_output)\n",
    "\n",
    "    print(\"Analysis complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    species = \"mouse\"\n",
    "    tissue_type = \"larynx\"\n",
    "    marker_list = [\"Krt5\", \"Trp63\", \"Krt14\", \"Cdh1\", \"Epcam\", \"Vim\", \"Cdh2\", \"Acta2\", \"Msln\", \"Upk3b\", \"Krt8\", \"Krt18\", \"Foxj1\", \"Tubb4b\", \"Scgb1a1\", \"Scgb3a2\", \"Muc5ac\", \"Muc5b\", \"Ltf\"]\n",
    "    additional_info = \"Focus on epithelial cell types\"\n",
    "    \n",
    "    run_analysis(species, tissue_type, marker_list, additional_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
